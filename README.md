# Tme AI Agent - Voice Engine

Há»‡ thá»‘ng AI Agent há»— trá»£ giá»ng nÃ³i vá»›i kháº£ nÄƒng Speech-to-Text (STT) realtime, tÃ¬m kiáº¿m thÃ´ng tin vÃ  tráº£ lá»i cÃ¢u há»i thÃ´ng minh.

## ğŸ“‹ TÃ­nh nÄƒng chÃ­nh

- **Speech-to-Text Realtime**: Chuyá»ƒn Ä‘á»•i giá»ng nÃ³i thÃ nh vÄƒn báº£n theo thá»i gian thá»±c qua WebSocket
- **AI Brain**: Xá»­ lÃ½ cÃ¢u há»i vÃ  tráº£ lá»i thÃ´ng minh sá»­ dá»¥ng LLM (Llama 3.1 via Groq)
- **TÃ¬m kiáº¿m Web**: TÃ­ch há»£p Tavily API Ä‘á»ƒ tÃ¬m kiáº¿m thÃ´ng tin realtime
- **Vector Database**: LÆ°u trá»¯ vÃ  truy váº¥n ngá»¯ cáº£nh vá»›i ChromaDB
- **Horizontal Scaling**: Há»— trá»£ scale workers vá»›i Kafka message queue
- **Notification**: ThÃ´ng bÃ¡o qua Telegram bot
- **Monitoring**: GiÃ¡m sÃ¡t há»‡ thá»‘ng vá»›i Prometheus

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| Backend API | FastAPI, Uvicorn |
| STT Engine | Faster-Whisper |
| LLM | Llama 3.1 (via Groq API) |
| Search | Tavily API |
| Vector DB | ChromaDB |
| Message Queue | Apache Kafka |
| Task Queue | Celery + Redis |
| Embeddings | HuggingFace (all-MiniLM-L6-v2) |
| Monitoring | Prometheus |
| Orchestration | Apache Airflow |
| Container | Docker, Docker Compose |

## ğŸ“ Cáº¥u trÃºc Project

```
Project_voice/
â”œâ”€â”€ API/
â”‚   â”œâ”€â”€ Search_OpenAI/          # Module Brain & Search
â”‚   â”‚   â”œâ”€â”€ brain.py            # Core AI Brain logic
â”‚   â”‚   â”œâ”€â”€ search.py           # Search manager
â”‚   â”‚   â”œâ”€â”€ database.py         # Database operations
â”‚   â”‚   â”œâ”€â”€ news_service.py     # News scraping service
â”‚   â”‚   â””â”€â”€ telegram_service.py # Telegram notifications
â”‚   â””â”€â”€ voice/                  # Module Voice Processing
â”‚       â”œâ”€â”€ main.py             # FastAPI app entry
â”‚       â”œâ”€â”€ model_loader.py     # Whisper model loader
â”‚       â”œâ”€â”€ audio_utils.py      # Audio processing utilities
â”‚       â”œâ”€â”€ tasks.py            # Celery tasks
â”‚       â””â”€â”€ routes/             # API routes
â”‚           â”œâ”€â”€ stt.py          # Speech-to-Text endpoints
â”‚           â”œâ”€â”€ search.py       # Search endpoints
â”‚           â””â”€â”€ metrics.py      # Prometheus metrics
â”œâ”€â”€ dags/                       # Airflow DAGs
â”œâ”€â”€ data/                       # Data storage (ChromaDB, SQLite)
â”œâ”€â”€ deploy/                     # Deployment configs
â”œâ”€â”€ font_end/                   # Frontend (HTML/JS)
â”œâ”€â”€ temp_audio/                 # Temporary audio files
â”œâ”€â”€ config.py                   # Configuration
â”œâ”€â”€ kafka_worker.py             # Kafka consumer worker
â”œâ”€â”€ kafka_monitor.py            # Kafka monitoring
â”œâ”€â”€ scheduler.py                # Task scheduler
â”œâ”€â”€ docker-compose.yaml         # Docker orchestration
â””â”€â”€ requirements.txt            # Python dependencies
```

## ğŸš€ CÃ i Ä‘áº·t & Cháº¡y

### YÃªu cáº§u
- Python 3.10+
- Docker & Docker Compose
- Redis (cho Celery)
- Kafka (cho message queue)

### 1. Clone vÃ  cÃ i Ä‘áº·t dependencies

```bash
git clone <repository-url>
cd Project_voice
pip install -r requirements.txt
```

### 2. Cáº¥u hÃ¬nh environment variables

Táº¡o file `.env`:

```env
# API Keys
GROQ_API_KEY=your_groq_api_key
TAVILY_API_KEY=your_tavily_api_key

# Telegram (Optional)
TELEGRAM_BOT_TOKEN=your_bot_token
TELEGRAM_CHAT_ID=your_chat_id

# Celery (Optional)
USE_CELERY=false

# Data Management
MAX_DATA_SIZE_MB=1024
CLEANUP_DAYS=30
```

### 3. Cháº¡y vá»›i Docker Compose (Recommended)

```bash
docker-compose up -d
```

Services sáº½ cháº¡y trÃªn:
- **STT API**: http://localhost:8000
- **ChromaDB**: http://localhost:8001
- **Kafka**: localhost:9092
- **Prometheus**: http://localhost:9090

### 4. Cháº¡y local (Development)

```bash
# Cháº¡y API server
uvicorn API.voice.main:app --host 0.0.0.0 --port 8000 --reload

# Cháº¡y Kafka worker (trong terminal khÃ¡c)
python kafka_worker.py
```

## ğŸ“¡ API Endpoints

### REST API

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/` | Health check |
| POST | `/v1/stt` | Upload audio file for transcription |
| POST | `/v1/search` | Search query |
| GET | `/v1/metrics` | Prometheus metrics |

### WebSocket

| Endpoint | Description |
|----------|-------------|
| `ws://localhost:8000/v1/stt` | Realtime speech-to-text streaming |

### VÃ­ dá»¥ sá»­ dá»¥ng WebSocket STT

```javascript
const ws = new WebSocket('ws://localhost:8000/v1/stt');

// Gá»­i audio chunks
ws.send(audioChunk); // Int16 PCM, 16kHz

// Nháº­n transcription
ws.onmessage = (event) => {
    const result = JSON.parse(event.data);
    console.log(result.text);
};
```

## âš™ï¸ Configuration

CÃ¡c tham sá»‘ trong `config.py`:

| Parameter | Default | Description |
|-----------|---------|-------------|
| `_SAMPLE_` | 16000 | Sample rate (Hz) |
| `_MIN_` | 0.3 | Minimum audio length (s) |
| `_MAX_` | 1.5 | Maximum audio chunk (s) |
| `_SILENCE_THRESHOLD_` | 0.002 | Silence detection threshold |
| `_SILENCE_DURATION_` | 0.4 | Silence duration to split (s) |

## ğŸ”§ Scaling

### Horizontal Scaling vá»›i Kafka Workers

```bash
# Scale brain workers
docker-compose up -d --scale brain-worker=5
```

### Celery Workers (Alternative)

```bash
celery -A API.voice.celery_app worker --loglevel=info --concurrency=4
```

## ğŸ“Š Monitoring

### Prometheus Metrics

Access metrics táº¡i: http://localhost:9090

Metrics bao gá»“m:
- Request latency
- Transcription time
- Error rates
- Worker status

### Kafka Monitoring

```bash
python kafka_monitor.py
```

## ğŸ§ª Testing

### Stress Test vá»›i Locust

```bash
locust -f locustfile.py --host=http://localhost:8000
```

### Evaluation Pipeline

```bash
python evaluation_pipeline.py
python analyze_evaluation.py
```

## ğŸ“¦ Deployment

### Production Deployment

```bash
cd deploy
chmod +x deploy.sh
./deploy.sh
```

Hoáº·c sá»­ dá»¥ng production compose:

```bash
docker-compose -f deploy/docker-compose.prod.yml up -d
```

## ğŸ”„ Scheduled Tasks

### Airflow DAGs

- `tme_morning_refresh.py`: Cáº­p nháº­t tin tá»©c buá»•i sÃ¡ng

### Manual News Refresh

```bash
python run_news_refresh.py
```

## ğŸ“ License

MIT License

## ğŸ‘¥ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request
